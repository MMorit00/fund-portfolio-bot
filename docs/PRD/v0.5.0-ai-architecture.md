è¿™æ˜¯åŸºäºæ·±åº¦å®¡æŸ¥æ„è§é‡æ„åçš„å®Œæ•´æŠ€æœ¯æŠ¥å‘Šã€‚æ­¤ç‰ˆæœ¬é‡‡ç”¨äº† **OpenAI å…¼å®¹åè®®ï¼ˆModel Agnosticï¼‰**ã€**Pydantic ç±»å‹é©±åŠ¨**ä»¥åŠ**ç»“æ„åŒ–è¾“å‡º**ç­‰ç°ä»£ AI å·¥ç¨‹æœ€ä½³å®è·µã€‚

# v0.5.1 AI åŸºç¡€æ¶æ„ - æŠ€æœ¯è°ƒç ”ä¸è®¾è®¡æŠ¥å‘Š

> **ç”Ÿæˆæ—¥æœŸ**ï¼š2025-12-23
> **ç‰ˆæœ¬**ï¼šv0.5.0 (Refined)
> **çŠ¶æ€**ï¼šè°ƒç ”å®Œæˆï¼Œå¾…å®ç°

---

## 1. æ‰§è¡Œæ‘˜è¦

ä¸ºæ„å»ºå¯æ‰©å±•ã€ä½æˆæœ¬ä¸”å·¥ç¨‹è§„èŒƒçš„ AI åŸºç¡€æ¶æ„ï¼Œæœ¬é¡¹ç›®å†³å®šæ‘’å¼ƒå‚å•†ä¸“ç”¨ SDKï¼Œè½¬è€Œé‡‡ç”¨ **OpenAI å…¼å®¹åè®®** ä½œä¸ºåº•å±‚æ ‡å‡†ã€‚

### æ ¸å¿ƒå†³ç­–

| å†³ç­–é¡¹ | ç»“è®º | æ ¸å¿ƒç†ç”± |
| --- | --- | --- |
| **åè®®æ ‡å‡†** | **OpenAI Compatible** | å½»åº•è§£è€¦æ¨¡å‹ä¾›åº”å•†ï¼Œä¸€è¡Œé…ç½®åˆ‡æ¢ GLM/Qwen/DeepSeek |
| **é¦–é€‰æ¨¡å‹** | **GLM-4-Flash** | æ™ºè°±é¦–æ¬¾å…è´¹/æä½æˆæœ¬æ¨¡å‹ï¼Œé€Ÿåº¦å¿«ï¼Œæ”¯æŒ Tools |
| **å¼€å‘æ¨¡å¼** | **Type-Driven (Pydantic)** | è‡ªåŠ¨ç”Ÿæˆ Schemaï¼Œå¼ºç±»å‹æ ¡éªŒï¼Œå‡å°‘ 50% æ ·æ¿ä»£ç  |
| **è¾“å‡ºæ¨¡å¼** | **Structured JSON** | å¼ºåˆ¶æ¨¡å‹è¾“å‡ºç»“æ„åŒ–æ•°æ®ï¼Œç”± CLI è´Ÿè´£æ¸²æŸ“ï¼Œæœç»è§£æå›°éš¾ |
| **æˆæœ¬ä¼°ç®—** | **â‰ˆ 0 å…ƒ** | åŸºäº GLM-4-Flash å…è´¹é¢åº¦/æä½è´¹ç‡ |

---

## 2. æ¶æ„å®šä½

### 2.1 æ ¸å¿ƒåŸåˆ™ï¼šåªè¯»ä¸éš”ç¦»

1. **ç‰©ç†éš”ç¦»**ï¼šAI è¿è¡Œåœ¨ç‹¬ç«‹è¿›ç¨‹/æ¨¡å—ï¼Œä¸ç›´æ¥è§¦ç¢°æ•°æ®åº“å†™æƒé™ã€‚
2. **å·¥å…·ç®—æ•°**ï¼šAI è´Ÿè´£æ„å›¾è¯†åˆ«å’Œæµç¨‹ç¼–æ’ï¼Œå¤æ‚è®¡ç®—ï¼ˆå¦‚æ”¶ç›Šç‡ã€å›æ’¤ï¼‰å…¨æƒå§”æ‰˜ç»™ Python å‡½æ•°ã€‚
3. **ä¸Šä¸‹æ–‡å®‰å…¨**ï¼šTool è¿”å›ç»“æœå¿…é¡»è¿›è¡Œâ€œå‹ç¼©â€æˆ–â€œæˆªæ–­â€ï¼Œé˜²æ­¢æ’‘çˆ† Context Windowã€‚

### 2.2 æ¶æ„åˆ†å±‚å›¾

```mermaid
graph TD
    User[ç”¨æˆ· (CLI)] --> |è‡ªç„¶è¯­è¨€| AICore
    
    subgraph "AI Infrastructure (Model Agnostic)"
        AICore[AI Client (OpenAI Lib)]
        Config[Env: BASE_URL / API_KEY] --> AICore
        
        subgraph "Protocol Layer"
            Req[Standard Request]
            Resp[Structured Response]
        end
        
        AICore --> |HTTP/SSE| Cloud[MaaS Provider]
        Cloud -.-> |GLM-4| Zhipu[æ™ºè°± AI]
        Cloud -.-> |Qwen| Ali[é˜¿é‡Œç™¾ç‚¼]
        Cloud -.-> |DeepSeek| DS[DeepSeek]
    end
    
    subgraph "Tool Layer (Pydantic)"
        Schema[Schema Generator] --> Tools
        Tools[Tool Functions]
        Tools --> |Read Only| DB[(ActionLog / Nav Table)]
    end
    
    AICore <--> |Tool Calls| Tools

```

---

## 3. æ¨¡å‹é€‰å‹å¯¹æ ‡ï¼ˆ2024.12 æ›´æ–°ç‰ˆï¼‰

é‰´äºå„å‚å•†å‡å·²æ”¯æŒ OpenAI åè®®ï¼Œé€‰å‹ä¸å†å— SDK é™åˆ¶ï¼Œä»…è€ƒé‡æ¨¡å‹èƒ½åŠ›ä¸æ€§ä»·æ¯”ã€‚

| ç»´åº¦ | **GLM-4-Flash** (æ™ºè°±) | **Qwen-Max** (é˜¿é‡Œ) | **DeepSeek-V3** |
| --- | --- | --- | --- |
| **å®šä½** | **MVP é¦–é€‰** | å¤‡é€‰ (å¤æ‚é€»è¾‘) | å¤‡é€‰ (ä»£ç /æ¨ç†å¼º) |
| **ä»·æ ¼** | **å…è´¹** / æä½ | è¾“å…¥ 0.0024/åƒ Token | è¾“å…¥ 0.001/åƒ Token |
| **åè®®å…¼å®¹** | âœ… å®Œç¾å…¼å®¹ | âœ… å®Œç¾å…¼å®¹ | âœ… å®Œç¾å…¼å®¹ |
| **Function Calling** | ç¨³å®šï¼Œæ”¯æŒå¹¶è¡Œ | æå¼º | æå¼º |
| **Tool Choice** | é»˜è®¤ä¸º auto | æ”¯æŒå¼ºåˆ¶æŒ‡å®š | æ”¯æŒå¼ºåˆ¶æŒ‡å®š |

**ç»“è®º**ï¼šMVP é˜¶æ®µä½¿ç”¨ **GLM-4-Flash**ï¼Œåˆ©ç”¨å…¶å…è´¹/ä½æˆæœ¬ç‰¹æ€§å¿«é€Ÿè·‘é€šé“¾è·¯ã€‚ä»£ç å±‚é€šè¿‡ç¯å¢ƒå˜é‡é¢„ç•™åˆ‡æ¢ Qwen/DeepSeek çš„èƒ½åŠ›ã€‚

---

## 4. æ ¸å¿ƒç»„ä»¶è®¾è®¡ (Modern Style)

### 4.1 ç›®å½•ç»“æ„

```text
src/
  ai/
    â”œâ”€ client.py           # é€šç”¨ AI å®¢æˆ·ç«¯ (OpenAI wrapper)
    â”œâ”€ schemas/            # Pydantic æ•°æ®æ¨¡å‹
    â”‚   â”œâ”€ arguments.py    # å·¥å…·å…¥å‚å®šä¹‰
    â”‚   â””â”€ responses.py    # AI è¾“å‡ºç»“æ„å®šä¹‰
    â”œâ”€ tools/              # å·¥å…·å‡½æ•°å®ç°
    â”‚   â”œâ”€ facts.py        # äº‹å®ç±»å·¥å…· (æŸ¥åº“)
    â”‚   â””â”€ calcs.py        # è®¡ç®—ç±»å·¥å…· (çº¯å‡½æ•°)
    â”œâ”€ prompts/
    â”‚   â””â”€ system.py       # ç³»ç»Ÿæç¤ºè¯ (å«æ—¶é—´æ³¨å…¥)
    â””â”€ registry.py         # Tool æ³¨å†Œè£…é¥°å™¨

```

### 4.2 ä¾èµ–ç®¡ç†

```toml
[project.dependencies]
openai = "^1.50.0"     # è¡Œä¸šæ ‡å‡†å®¢æˆ·ç«¯
pydantic = "^2.9.0"    # æ•°æ®æ ¡éªŒä¸ Schema ç”Ÿæˆ
rich = "^13.9.0"       # ç»ˆç«¯ç¾åŒ–è¾“å‡º

```

---

## 5. ä»£ç å®ç°ç»†èŠ‚

### 5.1 ç³»ç»Ÿæç¤ºè¯ (System Prompt)

å®Œæ•´çš„ç³»ç»Ÿæç¤ºè¯å®šä¹‰ï¼ŒåŒ…å«è§’è‰²çº¦æŸå’Œè¾“å‡ºæ ¼å¼è¦æ±‚ï¼š

```python
# src/ai/prompts/system.py

BASE_SYSTEM_PROMPT = """
# Role: åŸºé‡‘æŠ•èµ„åˆ†æåŠ©æ‰‹
# Expertise: ä¸ªäººèµ„äº§é…ç½®åˆ†æã€å®šæŠ•æ‰§è¡Œè¯„ä¼°ã€é£é™©æç¤º

## æ ¸å¿ƒçº¦æŸï¼ˆä¸¥æ ¼éµå®ˆï¼‰

### 1. æ•°æ®å‡†ç¡®æ€§
- æ‰€æœ‰æ•°æ®å¿…é¡»æ¥è‡ª Tool è¿”å›ç»“æœï¼Œä¸¥ç¦ç¼–é€ ä»»ä½•æ•°å€¼
- è‹¥ Tool è¿”å›ç©ºæˆ–é”™è¯¯ï¼Œç›´æ¥å‘ŠçŸ¥ç”¨æˆ·"æœªæŸ¥è¯¢åˆ°æ•°æ®"
- è‹¥æ•°æ®ä¸å®Œæ•´ï¼Œåœ¨ missing_data å­—æ®µä¸­åˆ—å‡ºç¼ºå¤±é¡¹

### 2. é‡‘èæ•°æ®è§„èŒƒ
- é‡‘é¢ï¼šä¿ç•™ 4 ä½å°æ•°ï¼ˆä¸ç³»ç»Ÿ Decimal ç²¾åº¦ç»Ÿä¸€ï¼‰
- ç™¾åˆ†æ¯”ï¼šå¸¦ % ç¬¦å·ï¼Œ2 ä½å°æ•°ï¼ˆå¦‚ 98.50%ï¼‰
- æ—¥æœŸï¼šYYYY-MM-DD æ ¼å¼
- åŸºé‡‘ä»£ç ï¼š6 ä½æ•°å­—ï¼Œè¡¥é½å‰å¯¼ 0

### 3. è¾“å‡ºæ ¼å¼
å¿…é¡»è¾“å‡ºä»¥ä¸‹ JSON ç»“æ„ï¼Œä¸å…è®¸å…¶ä»–æ ¼å¼ï¼š
{
    "summary": "ç®€çŸ­äº‹å®é™ˆè¿°ï¼ŒåŒ…å«å…³é”®æ•°æ®",
    "analysis": "æ·±åº¦åˆ†æï¼Œè§£é‡Šæ•°æ®èƒŒåçš„åŸå› ",
    "advice": "è¡ŒåŠ¨å»ºè®®ï¼ˆä»…ä¾›å‚è€ƒï¼Œä¸å«å…·ä½“ä¹°å–æŒ‡ä»¤ï¼‰",
    "risk_level": "low|medium|high",
    "missing_data": ["ç¼ºå¤±é¡¹1", "ç¼ºå¤±é¡¹2"]
}

### 4. ç¦æ­¢è¡Œä¸º
- ä¸ç¼–é€ å‡€å€¼ã€æ”¶ç›Šç‡ç­‰ä»»ä½•æ•°å€¼
- ä¸é¢„æµ‹å¸‚åœºèµ°åŠ¿
- ä¸ç»™å‡ºå…·ä½“ä¹°å–å»ºè®®ï¼ˆå¦‚"å»ºè®®ä¹°å…¥ XX åŸºé‡‘"ï¼‰
- ä¸æ‰§è¡Œä»»ä½•äº¤æ˜“æ“ä½œ

## æŸ¥è¯¢ç­–ç•¥
- ç”¨æˆ·è¯´"æœ€è¿‘" â†’ æ¨æ–­ä¸ºæœ€è¿‘ 30 å¤©
- ç”¨æˆ·è¯´"è¿™ä¸ªæœˆ" â†’ å½“æœˆ 1 æ—¥è‡³ä»Š
- ç”¨æˆ·é—®"å®šæŠ•æƒ…å†µ" â†’ è°ƒç”¨ query_dca_execution
- ç”¨æˆ·é—®"ä¸ºä»€ä¹ˆåå·®å¤§" â†’ å…ˆè°ƒç”¨ get_restriction_context æŸ¥é™é¢
"""
```

### 5.2 Tool æ³¨å†Œè£…é¥°å™¨

ä½¿ç”¨è£…é¥°å™¨ç»‘å®š Pydantic å‚æ•°æ¨¡å‹ï¼Œå®ç°ç±»å‹å®‰å…¨çš„å·¥å…·æ³¨å†Œï¼š

```python
# src/ai/registry.py
from typing import Type, Dict, Callable, Any
from pydantic import BaseModel
from functools import wraps

# å…¨å±€å·¥å…·æ³¨å†Œè¡¨
_TOOLS_REGISTRY: Dict[str, Callable] = {}

def tool(args_model: Type[BaseModel]):
    """
    Tool è£…é¥°å™¨ï¼Œç»‘å®šå‚æ•°æ¨¡å‹åˆ°å‡½æ•°

    ä½¿ç”¨æ–¹å¼ï¼š
        @tool(FundQueryArgs)
        def query_fund_nav(fund_code: str, query_date: str = None):
            '''æŸ¥è¯¢åŸºé‡‘å‡€å€¼'''
            ...
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ä½¿ç”¨ Pydantic éªŒè¯å‚æ•°
            validated = args_model(**kwargs)
            return func(**validated.model_dump())

        # ç»‘å®šå…ƒæ•°æ®
        wrapper.args_model = args_model
        wrapper.tool_name = func.__name__
        wrapper.description = func.__doc__ or ""

        # æ³¨å†Œåˆ°å…¨å±€è¡¨
        _TOOLS_REGISTRY[func.__name__] = wrapper

        return wrapper
    return decorator

def get_all_tools() -> Dict[str, Callable]:
    """è·å–æ‰€æœ‰å·²æ³¨å†Œçš„å·¥å…·"""
    return _TOOLS_REGISTRY.copy()

def get_tool_schemas() -> list:
    """ç”Ÿæˆæ‰€æœ‰å·¥å…·çš„ OpenAI Schema"""
    schemas = []
    for name, func in _TOOLS_REGISTRY.items():
        schemas.append({
            "type": "function",
            "function": {
                "name": name,
                "description": func.description,
                "parameters": func.args_model.model_json_schema()
            }
        })
    return schemas
```

### 5.3 ç»“æ„åŒ–è¾“å‡ºå®šä¹‰ (Response Schema)

å¼ºåˆ¶æ¨¡å‹è¿”å› JSONï¼Œä¾¿äºç¨‹åºå¤„ç†ï¼š

```python
# src/ai/schemas/responses.py
from pydantic import BaseModel, Field
from typing import Literal, List

class FinancialAnalysis(BaseModel):
    """AI æŠ•èµ„åˆ†æçš„æ ‡å‡†è¾“å‡ºç»“æ„"""

    summary: str = Field(..., description="ç®€çŸ­çš„äº‹å®é™ˆè¿°ï¼ŒåŒ…å«å…³é”®æ•°æ®")
    analysis: str = Field(..., description="æ·±åº¦åˆ†æï¼Œè§£é‡Šæ•°æ®èƒŒåçš„åŸå› ")
    advice: str = Field(..., description="å…·ä½“çš„è¡ŒåŠ¨å»ºè®®ï¼ˆæ³¨æ„ï¼šä¸åŒ…å«å…·ä½“ä¹°å–æŒ‡ä»¤ï¼Œä»…ä½œä¸ºå‚è€ƒï¼‰")
    risk_level: Literal["low", "medium", "high"] = Field(..., description="é£é™©ç­‰çº§è¯„ä¼°")
    missing_data: List[str] = Field(default_factory=list, description="åˆ†æä¸­ç¼ºå¤±çš„æ•°æ®é¡¹ï¼Œå¦‚æœ‰")

```

### 5.4 å·¥å…·å‚æ•°å®šä¹‰ (Arguments Schema)

å‘Šåˆ«æ‰‹å†™ JSON Schemaï¼Œä½¿ç”¨ Type Hint + Pydantic è‡ªåŠ¨ç”Ÿæˆï¼š

```python
# src/ai/schemas/arguments.py
from pydantic import BaseModel, Field
from typing import Optional, Literal

class FundQueryArgs(BaseModel):
    """æŸ¥è¯¢åŸºé‡‘å‡€å€¼å·¥å…·å‚æ•°"""
    fund_code: str = Field(..., pattern=r"^\d{6}$", description="6ä½æ•°å­—åŸºé‡‘ä»£ç ")
    query_date: Optional[str] = Field(None, description="æŸ¥è¯¢æ—¥æœŸ YYYY-MM-DDï¼Œé»˜è®¤ä»Šå¤©")

class DcaExecutionArgs(BaseModel):
    """æŸ¥è¯¢å®šæŠ•æ‰§è¡Œæƒ…å†µå‚æ•°"""
    fund_code: str = Field(..., description="6ä½æ•°å­—åŸºé‡‘ä»£ç ")
    period: Literal["1m", "3m", "6m", "ytd"] = Field("1m", description="æŸ¥è¯¢å‘¨æœŸï¼šè¿‘1æœˆ/3æœˆ/6æœˆ/ä»Šå¹´ä»¥æ¥")

class RestrictionContextArgs(BaseModel):
    """æŸ¥è¯¢é™é¢ä¸Šä¸‹æ–‡å‚æ•°"""
    fund_code: str = Field(..., description="6ä½æ•°å­—åŸºé‡‘ä»£ç ")
    query_date: Optional[str] = Field(None, description="æŸ¥è¯¢æ—¥æœŸ YYYY-MM-DD")

```

### 5.5 é€šç”¨å®¢æˆ·ç«¯å®ç° (OpenAI Compatible)

è¿™æ˜¯æœ¬æ¶æ„ä¸­æœ€å…³é”®çš„"é€‚é…å±‚"ï¼ŒåŒ…å«å®Œæ•´çš„é”™è¯¯å¤„ç†ä¸é‡è¯•æœºåˆ¶ï¼š

```python
# src/ai/client.py
import os
import json
import time
import logging
from typing import Dict, Any, Optional
from datetime import datetime
from openai import OpenAI, APIError, APITimeoutError, RateLimitError
from src.ai.prompts.system import BASE_SYSTEM_PROMPT
from src.ai.registry import get_all_tools, get_tool_schemas

logger = logging.getLogger(__name__)

class AIClient:
    """
    é€šç”¨ AI å®¢æˆ·ç«¯ï¼ˆOpenAI å…¼å®¹åè®®ï¼‰

    é€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶æ¥å…¥æ–¹ï¼Œä»£ç é›¶ä¿®æ”¹åˆ‡æ¢æ¨¡å‹ï¼š
    - LLM_BASE_URL: API ç«¯ç‚¹
    - LLM_API_KEY: API å¯†é’¥
    - LLM_MODEL: æ¨¡å‹åç§°
    """

    def __init__(self):
        self.client = OpenAI(
            api_key=os.getenv("LLM_API_KEY"),
            base_url=os.getenv("LLM_BASE_URL", "https://open.bigmodel.cn/api/paas/v4/"),
            timeout=30.0,
        )
        self.model = os.getenv("LLM_MODEL", "glm-4-flash")
        self.max_retries = int(os.getenv("LLM_MAX_RETRIES", "3"))

    def _call_with_retry(self, func, *args, **kwargs) -> Any:
        """å¸¦æŒ‡æ•°é€€é¿çš„é‡è¯•æœºåˆ¶"""
        last_error = None
        for attempt in range(self.max_retries):
            try:
                return func(*args, **kwargs)
            except RateLimitError as e:
                last_error = e
                wait_time = 2 ** attempt
                logger.warning(f"[AIClient] è§¦å‘é™æµï¼Œç­‰å¾… {wait_time}s åé‡è¯• ({attempt + 1}/{self.max_retries})")
                time.sleep(wait_time)
            except APITimeoutError as e:
                last_error = e
                logger.warning(f"[AIClient] è¯·æ±‚è¶…æ—¶ï¼Œé‡è¯• ({attempt + 1}/{self.max_retries})")
            except APIError as e:
                last_error = e
                if e.status_code >= 500:
                    logger.warning(f"[AIClient] æœåŠ¡ç«¯é”™è¯¯ {e.status_code}ï¼Œé‡è¯• ({attempt + 1}/{self.max_retries})")
                    time.sleep(1)
                else:
                    raise  # 4xx é”™è¯¯ä¸é‡è¯•
        raise last_error

    def chat(self, query: str, tools_map: Optional[Dict[str, Any]] = None) -> str:
        """
        æ‰§è¡Œå¯¹è¯

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            tools_map: å·¥å…·æ˜ å°„è¡¨ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€æ³¨å†Œçš„å·¥å…·

        Returns:
            AI å“åº”ï¼ˆJSON å­—ç¬¦ä¸²ï¼‰
        """
        if tools_map is None:
            tools_map = get_all_tools()

        # 1. æ„å»ºæ¶ˆæ¯
        current_context = f"Current Date: {datetime.now().strftime('%Y-%m-%d')}"
        system_content = f"{BASE_SYSTEM_PROMPT}\n\n{current_context}"

        messages = [
            {"role": "system", "content": system_content},
            {"role": "user", "content": query}
        ]

        # 2. æ„å»ºå·¥å…·å®šä¹‰
        tool_schemas = get_tool_schemas() if tools_map else None

        # 3. åˆæ¬¡è°ƒç”¨
        logger.info(f"[AIClient] å‘é€æŸ¥è¯¢: {query[:50]}...")
        response = self._call_with_retry(
            self.client.chat.completions.create,
            model=self.model,
            messages=messages,
            tools=tool_schemas,
            temperature=0.1  # é‡‘èåœºæ™¯ä½æ¸©
        )

        msg = response.choices[0].message

        # 4. å¤„ç† Tool Calls
        if msg.tool_calls:
            messages.append(msg)

            for tool_call in msg.tool_calls:
                func_name = tool_call.function.name
                logger.info(f"[AIClient] è°ƒç”¨å·¥å…·: {func_name}")

                try:
                    args = json.loads(tool_call.function.arguments)
                    if func_name in tools_map:
                        result = tools_map[func_name](**args)
                    else:
                        result = {"error": f"æœªçŸ¥å·¥å…·: {func_name}"}
                except json.JSONDecodeError as e:
                    result = {"error": f"å‚æ•°è§£æå¤±è´¥: {e}"}
                except Exception as e:
                    logger.error(f"[AIClient] å·¥å…·æ‰§è¡Œå¤±è´¥: {func_name} - {e}")
                    result = {"error": str(e), "hint": "è¯·æ£€æŸ¥å‚æ•°æˆ–ç¨åé‡è¯•"}

                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "content": json.dumps(result, ensure_ascii=False)
                })

            # 5. äºŒæ¬¡è°ƒç”¨ï¼Œè·å–æœ€ç»ˆåˆ†æ
            final_resp = self._call_with_retry(
                self.client.chat.completions.create,
                model=self.model,
                messages=messages,
                response_format={"type": "json_object"}  # å¼ºåˆ¶ JSON
            )
            return final_resp.choices[0].message.content

        return msg.content or ""

```

---

## 6. å·¥å…·å‡½æ•°è®¾è®¡ï¼ˆäº‹å®ä¸è®¡ç®—åˆ†ç¦»ï¼‰

### 6.1 è®¾è®¡åŸåˆ™

* **Fact Tools**: ä»…è´Ÿè´£æŸ¥åº“ï¼Œä¸åšä¸šåŠ¡åˆ¤æ–­ã€‚
* **Calc Tools**: çº¯å‡½æ•°ï¼Œè¾“å…¥åŸå§‹æ•°æ®ï¼Œè¾“å‡ºæŒ‡æ ‡ã€‚
* **Safety**: å¿…é¡»åŒ…å«è¡Œæ•°é™åˆ¶ (Limit)ã€‚

### 6.2 å®ç°ç¤ºä¾‹

ä½¿ç”¨ `@tool` è£…é¥°å™¨æ³¨å†Œå·¥å…·å‡½æ•°ï¼š

```python
# src/ai/tools/facts.py
from typing import Dict, Any, Optional
from datetime import date
from src.ai.registry import tool
from src.ai.schemas.arguments import FundQueryArgs, DcaExecutionArgs, RestrictionContextArgs
from src.core.dependency import dependency
from src.data.db.nav_repo import NavRepo
from src.data.db.trade_repo import TradeRepo

# æ•°æ®è¡Œæ•°é™åˆ¶ï¼Œé˜²æ­¢ä¸Šä¸‹æ–‡æº¢å‡º
MAX_ROWS = 50

@tool(FundQueryArgs)
@dependency
def query_fund_nav(
    fund_code: str,
    query_date: Optional[str] = None,
    *,
    nav_repo: NavRepo
) -> Dict[str, Any]:
    """æŸ¥è¯¢åŸºé‡‘çš„æœ€æ–°å‡€å€¼ï¼Œè¿”å›å‡€å€¼ã€æ—¥æœŸã€æ¶¨è·Œå¹…"""
    target_date = date.fromisoformat(query_date) if query_date else None
    nav = nav_repo.get_latest(fund_code, target_date)

    if not nav:
        return {"error": f"æœªæ‰¾åˆ°åŸºé‡‘ {fund_code} çš„å‡€å€¼æ•°æ®"}

    return {
        "fund_code": fund_code,
        "nav": str(nav.nav),
        "nav_date": nav.nav_date.isoformat(),
        "change_rate": f"{nav.change_rate:.2f}%" if nav.change_rate else None
    }

@tool(DcaExecutionArgs)
@dependency
def query_dca_execution(
    fund_code: str,
    period: str = "1m",
    *,
    trade_repo: TradeRepo
) -> Dict[str, Any]:
    """æŸ¥è¯¢å®šæŠ•æ‰§è¡Œæƒ…å†µï¼Œè¿”å›æ‰§è¡Œæ¬¡æ•°ã€æ€»é‡‘é¢ã€æ‰§è¡Œç‡ç­‰ç»Ÿè®¡"""
    # è®¡ç®—æ—¥æœŸèŒƒå›´
    end_date = date.today()
    period_days = {"1m": 30, "3m": 90, "6m": 180, "ytd": (end_date - date(end_date.year, 1, 1)).days}
    start_date = end_date - timedelta(days=period_days.get(period, 30))

    # æŸ¥è¯¢äº¤æ˜“ï¼ˆå¸¦è¡Œæ•°é™åˆ¶ï¼‰
    trades = trade_repo.list_by_fund_and_period(fund_code, start_date, end_date, limit=MAX_ROWS)
    dca_trades = [t for t in trades if t.strategy == "dca"]

    result = {
        "fund_code": fund_code,
        "period": f"{start_date.isoformat()} ~ {end_date.isoformat()}",
        "actual_count": len(dca_trades),
        "total_amount": str(sum(t.amount for t in dca_trades)),
    }

    # æ•°æ®æˆªæ–­è­¦å‘Š
    if len(trades) == MAX_ROWS:
        result["warning"] = f"æ•°æ®å·²æˆªæ–­ï¼Œä»…æ˜¾ç¤ºæœ€è¿‘ {MAX_ROWS} æ¡è®°å½•"

    return result

```

```python
# src/ai/tools/calcs.py
from typing import Dict, Any, List
from decimal import Decimal

def calc_execution_rate(expected: int, actual: int) -> Dict[str, Any]:
    """
    è®¡ç®—å®šæŠ•æ‰§è¡Œç‡
    çº¯è®¡ç®—å‡½æ•°ï¼Œä¸è®¿é—®æ•°æ®åº“
    """
    if expected == 0:
        return {"error": "é¢„æœŸæ¬¡æ•°ä¸èƒ½ä¸º 0"}

    rate = actual / expected * 100
    return {
        "expected": expected,
        "actual": actual,
        "rate": f"{rate:.1f}%",
        "status": "æ­£å¸¸" if rate >= 90 else "åä½" if rate >= 70 else "å¼‚å¸¸"
    }

```

---

## 7. CLI è¾“å‡ºè®¾è®¡ (Rich Render)

å‰ç«¯å±•ç¤ºé€»è¾‘ä¸ AI é€»è¾‘è§£è€¦ã€‚

```python
# src/cli/ai.py
import json
from rich.console import Console
from rich.panel import Panel
from rich.markdown import Markdown
from src.ai.schemas.responses import FinancialAnalysis

console = Console()

def render_ai_response(json_str: str):
    try:
        # 1. éªŒè¯ç»“æ„
        data = FinancialAnalysis.model_validate_json(json_str)
        
        # 2. æ¸²æŸ“é£é™©å¾½ç« 
        risk_color = {"low": "green", "medium": "yellow", "high": "red"}
        risk_badge = f"[{risk_color[data.risk_level]}]Risk: {data.risk_level.upper()}[/]"
        
        # 3. ç»„åˆé¢æ¿
        content = f"""
        ### ğŸ“Š æ¦‚è§ˆ
        {data.summary}
        
        ### ğŸ§ æ·±åº¦åˆ†æ
        {data.analysis}
        
        ### ğŸ’¡ å»ºè®®
        {data.advice}
        """
        
        console.print(Panel(
            Markdown(content), 
            title=f"AI Investment Analyst  |  {risk_badge}",
            border_style="blue"
        ))
        
    except Exception as e:
        console.print(f"[red]è§£æ AI å“åº”å¤±è´¥: {e}[/red]")
        console.print(json_str) # é™çº§æ˜¾ç¤ºåŸå§‹æ–‡æœ¬

```

---

## 8. ç¯å¢ƒå˜é‡é…ç½®

ä¸å†éœ€è¦ç‰¹å®šå‚å•†çš„é…ç½®ï¼Œæ”¹ä¸ºé€šç”¨ OpenAI å…¼å®¹é…ç½®ï¼š

```bash
# .env

# ==================== LLM æ ¸å¿ƒé…ç½® ====================

# æ–¹æ¡ˆ A: æ™ºè°± GLM-4-Flash (å…è´¹/ä½æˆæœ¬) [æ¨è MVP]
LLM_BASE_URL=https://open.bigmodel.cn/api/paas/v4/
LLM_API_KEY=your_zhipu_key
LLM_MODEL=glm-4-flash

# æ–¹æ¡ˆ B: é˜¿é‡Œ Qwen (è‹¥éœ€è¦æ›´å¼ºæ¨ç†)
# LLM_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
# LLM_API_KEY=your_dashscope_key
# LLM_MODEL=qwen-max

# æ–¹æ¡ˆ C: DeepSeek (ä»£ç /æ¨ç†èƒ½åŠ›å¼º)
# LLM_BASE_URL=https://api.deepseek.com/v1
# LLM_API_KEY=your_deepseek_key
# LLM_MODEL=deepseek-chat

# æ–¹æ¡ˆ D: æœ¬åœ° Ollama (è°ƒè¯•ç”¨)
# LLM_BASE_URL=http://localhost:11434/v1
# LLM_API_KEY=ollama
# LLM_MODEL=qwen2.5:7b

# ==================== LLM å¯é€‰é…ç½® ====================

# æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤ 3ï¼‰
LLM_MAX_RETRIES=3

# è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼Œç§’ï¼ˆé»˜è®¤ 30ï¼‰
LLM_TIMEOUT=30

# æ˜¯å¦å¯ç”¨è°ƒè¯•æ—¥å¿—ï¼ˆé»˜è®¤ falseï¼‰
LLM_DEBUG=false

```

### 8.1 é…ç½®è¯»å–

```python
# src/core/config.pyï¼ˆè¡¥å……ï¼‰
import os

class AIConfig:
    """AI ç›¸å…³é…ç½®"""

    @staticmethod
    def get_base_url() -> str:
        return os.getenv("LLM_BASE_URL", "https://open.bigmodel.cn/api/paas/v4/")

    @staticmethod
    def get_api_key() -> str:
        key = os.getenv("LLM_API_KEY")
        if not key:
            raise ValueError("LLM_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
        return key

    @staticmethod
    def get_model() -> str:
        return os.getenv("LLM_MODEL", "glm-4-flash")

    @staticmethod
    def get_max_retries() -> int:
        return int(os.getenv("LLM_MAX_RETRIES", "3"))

    @staticmethod
    def get_timeout() -> float:
        return float(os.getenv("LLM_TIMEOUT", "30"))

    @staticmethod
    def is_debug() -> bool:
        return os.getenv("LLM_DEBUG", "false").lower() == "true"
```

---

## 9. å®æ–½è·¯çº¿å›¾

### Phase 1: éª¨æ¶æ„å»º (3å¤©)

1. [ ] å®‰è£… `openai`, `pydantic`ã€‚
2. [ ] å®ç° `AIClient` ç±»ï¼Œè·‘é€š "Hello World" (æŒ‡é’ˆå¯¹æ¥ GLM-4)ã€‚
3. [ ] å®šä¹‰ `FinancialAnalysis` Pydantic æ¨¡å‹ã€‚

### Phase 2: å·¥å…·é“¾å®ç° (5å¤©)

1. [ ] å®ç° `FundQueryArgs` ç­‰å…¥å‚æ¨¡å‹ã€‚
2. [ ] å®ç° 3 ä¸ªæ ¸å¿ƒ Tools (å‡€å€¼ã€å®šæŠ•ç»Ÿè®¡ã€é™é¢ä¸Šä¸‹æ–‡)ã€‚
3. [ ] **å…³é”®ç‚¹**ï¼šå®ç° Tool å†…éƒ¨çš„â€œæ•°æ®æˆªæ–­â€ä¿æŠ¤é€»è¾‘ã€‚

### Phase 3: CLI é›†æˆ (2å¤©)

1. [ ] é›†æˆ `rich` åº“æ¸²æŸ“ JSONã€‚
2. [ ] ç¼–å†™ System Promptï¼Œæ³¨å…¥ `{current_date}`ã€‚
3. [ ] è”è°ƒæµ‹è¯•ã€‚

---

## 10. é£é™©ä¸ç¼“è§£

| é£é™© | å¯èƒ½æ€§ | ç¼“è§£æ–¹æ¡ˆ |
| --- | --- | --- |
| **JSON è§£æå¤±è´¥** | ä¸­ | `json_object` æ¨¡å¼ + Pydantic æ ¡éªŒ + é”™è¯¯é‡è¯•æœºåˆ¶ |
| **ä¸Šä¸‹æ–‡æº¢å‡º** | é«˜ | Tool å†…éƒ¨ç¡¬æ€§é™åˆ¶è¿”å›è¡Œæ•° (Limit 50) + ç»“æœæ‘˜è¦ |
| **æ¨¡å‹ç®—æ•°é”™è¯¯** | ä¸­ | ä¸¥ç¦æ¨¡å‹è®¡ç®—ï¼Œå¼ºåˆ¶è°ƒç”¨ Calculator Tool |
| **å‚å•† API å˜æ›´** | ä½ | å·²é€šè¿‡ OpenAI åè®®å±‚è§£è€¦ï¼Œå½±å“å¾®ä¹å…¶å¾® |
| **API é™æµ/ä¸å¯ç”¨** | ä¸­ | æŒ‡æ•°é€€é¿é‡è¯• + é™çº§æç¤º |

---

## 11. æ—¥å¿—è§„èŒƒ

éµå¾ªé¡¹ç›®ç»Ÿä¸€çš„æ—¥å¿—å‰ç¼€è§„èŒƒï¼š

```python
# AI å±‚æ—¥å¿—å‰ç¼€
[AIClient]   - LLM API è°ƒç”¨ç›¸å…³ï¼ˆè¯·æ±‚ã€å“åº”ã€é‡è¯•ï¼‰
[AITools]    - å·¥å…·å‡½æ•°æ‰§è¡Œç›¸å…³ï¼ˆè°ƒç”¨ã€ç»“æœã€é”™è¯¯ï¼‰
[AIRegistry] - å·¥å…·æ³¨å†Œç›¸å…³

# ç¤ºä¾‹
logger.info("[AIClient] å‘é€æŸ¥è¯¢: å¤©å¼˜ä½™é¢å®å®šæŠ•æƒ…å†µ...")
logger.info("[AIClient] è°ƒç”¨å·¥å…·: query_fund_nav")
logger.warning("[AIClient] è§¦å‘é™æµï¼Œç­‰å¾… 2s åé‡è¯• (1/3)")
logger.error("[AITools] å·¥å…·æ‰§è¡Œå¤±è´¥: query_fund_nav - åŸºé‡‘ä¸å­˜åœ¨")
```

**æ•æ„Ÿä¿¡æ¯ä¿æŠ¤**ï¼š
- ä¸è®°å½• API Key
- ä¸è®°å½•å®Œæ•´ç”¨æˆ·æŸ¥è¯¢ï¼ˆæˆªæ–­è‡³ 50 å­—ç¬¦ï¼‰
- ä¸è®°å½•å…·ä½“åŸºé‡‘ä»£ç å’Œé‡‘é¢ï¼ˆå¯é…ç½®ï¼‰

---

## é™„å½• A: ä¾èµ–æ¸…å•

```toml
# pyproject.toml æ–°å¢ä¾èµ–
[project.dependencies]
openai = "^1.50.0"      # OpenAI å…¼å®¹å®¢æˆ·ç«¯
pydantic = "^2.9.0"     # æ•°æ®æ ¡éªŒä¸ Schema ç”Ÿæˆ
rich = "^13.9.0"        # ç»ˆç«¯ç¾åŒ–è¾“å‡ºï¼ˆå¯é€‰ï¼‰
```

## é™„å½• B: ç›®å½•ç»“æ„å®Œæ•´è§†å›¾

```text
src/
â”œâ”€ ai/
â”‚   â”œâ”€ __init__.py
â”‚   â”œâ”€ client.py              # AIClient å®ç°
â”‚   â”œâ”€ registry.py            # @tool è£…é¥°å™¨ & æ³¨å†Œè¡¨
â”‚   â”œâ”€ schemas/
â”‚   â”‚   â”œâ”€ __init__.py
â”‚   â”‚   â”œâ”€ arguments.py       # å·¥å…·å…¥å‚ Pydantic æ¨¡å‹
â”‚   â”‚   â””â”€ responses.py       # AI è¾“å‡º Pydantic æ¨¡å‹
â”‚   â”œâ”€ tools/
â”‚   â”‚   â”œâ”€ __init__.py
â”‚   â”‚   â”œâ”€ facts.py           # äº‹å®ç±»å·¥å…·ï¼ˆæŸ¥åº“ï¼‰
â”‚   â”‚   â””â”€ calcs.py           # è®¡ç®—ç±»å·¥å…·ï¼ˆçº¯å‡½æ•°ï¼‰
â”‚   â””â”€ prompts/
â”‚       â”œâ”€ __init__.py
â”‚       â””â”€ system.py          # ç³»ç»Ÿæç¤ºè¯
â”œâ”€ cli/
â”‚   â””â”€ ai.py                  # CLI å…¥å£ & Rich æ¸²æŸ“
â””â”€ ...
```

## é™„å½• C: å¿«é€ŸéªŒè¯è„šæœ¬

```python
# scripts/test_ai_hello.py
"""å¿«é€ŸéªŒè¯ AI å®¢æˆ·ç«¯æ˜¯å¦æ­£å¸¸å·¥ä½œ"""
import os
from dotenv import load_dotenv

load_dotenv()

def test_hello():
    from src.ai.client import AIClient

    client = AIClient()
    response = client.chat("ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»è‡ªå·±", tools_map={})
    print(f"AI å“åº”: {response}")
    assert response, "AI å“åº”ä¸ºç©º"
    print("âœ… AI å®¢æˆ·ç«¯éªŒè¯é€šè¿‡")

if __name__ == "__main__":
    test_hello()
```

è¿è¡Œæ–¹å¼ï¼š
```bash
uv run python scripts/test_ai_hello.py
```

---

**æ–‡æ¡£ç»“æŸ**